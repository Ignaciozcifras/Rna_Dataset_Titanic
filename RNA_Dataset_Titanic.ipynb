{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4516bd",
   "metadata": {},
   "source": [
    "# RNA Dataset Titanic\n",
    "## Curso Machine Learning Avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665c3e9",
   "metadata": {},
   "source": [
    "### Importación de librerías y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c6bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07146165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el dataset de entrenamiento\n",
    "dataset = pd.read_csv(\"/Users/joseignaciozamora/Desktop/Macbook/Magister/Magister/Machine Learning Avanzado/MLA DB/titanic/train.csv\")\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92b5d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83093",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5250de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna Cabin dado que tiene pocos datos y nos hace imposible poder normalizar nuestro dataset.\n",
    "#Al igual que PassengerId, Name y Ticket que no son representativas para el analisis, por ende, las eliminamos.\n",
    "\n",
    "dataset_2 = dataset.drop([\"Cabin\",\"PassengerId\", \"Name\", \"Ticket\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d428ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La moda de Emarked es: 0    S\n",
      "Name: Embarked, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Aun nos queda rellenar los embarked que son 2 datos y rellenaremos con la moda.\n",
    "\n",
    "moda = dataset_2.Embarked.mode()\n",
    "\n",
    "dataset_2.loc[dataset_2.Embarked.isnull(), \"Embarked\"] = \"S\"\n",
    "print(f\"La moda de Emarked es: {moda}\")\n",
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaebdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertimos las columnas Sex y Embarked en valores.\n",
    "def valores(x):\n",
    "    x['Sex'].replace('female', 0,inplace=True)\n",
    "    x['Sex'].replace('male', 1,inplace=True)\n",
    "    x['Embarked'].replace('S', 0,inplace=True)\n",
    "    x['Embarked'].replace('C', 1,inplace=True)\n",
    "    x['Embarked'].replace('Q', 2,inplace=True)\n",
    "valores(dataset_2)\n",
    "len(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22089e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vemos graficamente la perdida de información de las columnas, esto nos indica una fuerte perdida de información,\n",
    "#en la columna Age y unas cuantas en Embarked.\n",
    "\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "\n",
    "rgb_Color = (40/255, 116/255, 166/255)\n",
    "msno.matrix(dataset_2, color= rgb_Color, sparkline = False , figsize=(10,5), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe5f40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    int64  \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 55.8 KB\n"
     ]
    }
   ],
   "source": [
    "#Dado que son tan pocos datos, no eliminaremos las filas sin información, por ende,\n",
    "#procederemos a rellenar la información con la media de valores en base a Supervivencia, Sexo y Cabina.\n",
    "\n",
    "for s in range(0, 2):\n",
    "    for c in range(1, 4):\n",
    "        for g in range(0,2):\n",
    "            mean = (dataset_2.Age[(dataset_2.Survived == s) & (dataset_2.Pclass == c) & (dataset_2.Sex == g)].mean())\n",
    "            dataset_2.loc[(dataset_2.Age.isnull()) & (dataset_2.Survived == s) & (dataset_2.Pclass == c) & (dataset_2.Sex == g), \"Age\"] = mean   \n",
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9d9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age     15.0000\n",
      "Fare    23.0896\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Reescalamos las edades y tarifas con RobustScaler para elimimar el efecto de los outliers\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Revisamos los outliers\n",
    "Q1 = dataset_2[[\"Age\",\"Fare\"]].quantile(0.25)\n",
    "Q3 = dataset_2[[\"Age\",\"Fare\"]].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "RS = RobustScaler(with_centering=False, with_scaling=True)\n",
    "dataset_2[[\"Age\",\"Fare\"]] = RS.fit_transform(dataset_2[[\"Age\",\"Fare\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4eab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.313994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.533333</td>\n",
       "      <td>3.087247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>0.343228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.299737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.348642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.563024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.299286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.587879</td>\n",
       "      <td>1.015609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>1.299286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2.133333</td>\n",
       "      <td>0.335649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age      Fare\n",
       "0    1.466667  0.313994\n",
       "1    2.533333  3.087247\n",
       "2    1.733333  0.343228\n",
       "3    2.333333  2.299737\n",
       "4    2.333333  0.348642\n",
       "..        ...       ...\n",
       "886  1.800000  0.563024\n",
       "887  1.266667  1.299286\n",
       "888  1.587879  1.015609\n",
       "889  1.733333  1.299286\n",
       "890  2.133333  0.335649\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2[[\"Age\",\"Fare\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3661e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.087247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.299737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.348642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.299286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587879</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.299286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335649</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0         3    1  1.466667      1      0  0.313994         0\n",
       "1         1    0  2.533333      1      0  3.087247         1\n",
       "2         3    0  1.733333      0      0  0.343228         0\n",
       "3         1    0  2.333333      1      0  2.299737         0\n",
       "4         3    1  2.333333      0      0  0.348642         0\n",
       "..      ...  ...       ...    ...    ...       ...       ...\n",
       "886       2    1  1.800000      0      0  0.563024         0\n",
       "887       1    0  1.266667      0      0  1.299286         0\n",
       "888       3    0  1.587879      1      2  1.015609         0\n",
       "889       1    1  1.733333      0      0  1.299286         1\n",
       "890       3    1  2.133333      0      0  0.335649         2\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_X = dataset_2.drop(\"Survived\", axis =1)\n",
    "titanic_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0915d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y armamos nuestro dataset y_train\n",
    "titanic_y = dataset_2[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa715c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "#Los convertemos en arreglos de numpy\n",
    "titanic_X = np.array(titanic_X)\n",
    "titanic_y = np.array(titanic_y)\n",
    "\n",
    "#Y los normalizamos\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "titanic_X_norm = normalize(titanic_X)\n",
    "print(len(titanic_X_norm))\n",
    "print(len(titanic_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c7fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(titanic_X_norm, titanic_y, test_size= 0.9, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23297706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros de la RNA\n",
    "\n",
    "hidden_units = 10     # how many neurons in the hidden layer\n",
    "activation = 'relu'   # activation function for hidden layer\n",
    "l2 = 0.001             # regularization - how much we penalize large parameter values\n",
    "                     \n",
    "learning_rate = 0.001  # how big our steps are in gradient descent\n",
    "epochs = 300            # how many epochs to train for\n",
    "batch_size = 30       # how many samples to use for each gradient descent update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df4f1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corroboramos la cantidad de datos en nuestros sets de entrenamiento\n",
    "print(len(titanic_X_norm))\n",
    "print(len(titanic_y))\n",
    "\n",
    "\n",
    "#Creamos un arreglo con la cantidad de columnas del set de entrenamiento X.\n",
    "titanic_x_names = pd.DataFrame(titanic_X_norm).columns.values\n",
    "titanic_x_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "483c3a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 6/30 [=====>........................] - ETA: 0s - loss: 3.7029 - accuracy: 0.5889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 20:23:39.011590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 2.4082 - accuracy: 0.6162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 20:23:39.506024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 20ms/step - loss: 2.4082 - accuracy: 0.6162 - val_loss: 1.3319 - val_accuracy: 0.6110\n",
      "Epoch 2/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.1173 - accuracy: 0.6162 - val_loss: 1.0123 - val_accuracy: 0.6110\n",
      "Epoch 3/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.9323 - accuracy: 0.6162 - val_loss: 0.8689 - val_accuracy: 0.6110\n",
      "Epoch 4/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.7884 - accuracy: 0.6162 - val_loss: 0.7386 - val_accuracy: 0.6110\n",
      "Epoch 5/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6988 - accuracy: 0.6162 - val_loss: 0.6750 - val_accuracy: 0.6110\n",
      "Epoch 6/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6600 - accuracy: 0.6162 - val_loss: 0.6521 - val_accuracy: 0.6135\n",
      "Epoch 7/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.6444 - accuracy: 0.6263 - val_loss: 0.6402 - val_accuracy: 0.6446\n",
      "Epoch 8/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6332 - accuracy: 0.6498 - val_loss: 0.6295 - val_accuracy: 0.6521\n",
      "Epoch 9/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.6611 - val_loss: 0.6178 - val_accuracy: 0.6721\n",
      "Epoch 10/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6099 - accuracy: 0.6712 - val_loss: 0.6054 - val_accuracy: 0.6820\n",
      "Epoch 11/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5976 - accuracy: 0.6824 - val_loss: 0.5927 - val_accuracy: 0.6783\n",
      "Epoch 12/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5841 - accuracy: 0.6846 - val_loss: 0.5792 - val_accuracy: 0.6895\n",
      "Epoch 13/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5705 - accuracy: 0.6970 - val_loss: 0.5658 - val_accuracy: 0.6983\n",
      "Epoch 14/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5572 - accuracy: 0.7082 - val_loss: 0.5519 - val_accuracy: 0.7007\n",
      "Epoch 15/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.5425 - accuracy: 0.7093 - val_loss: 0.5388 - val_accuracy: 0.7070\n",
      "Epoch 16/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.7194 - val_loss: 0.5276 - val_accuracy: 0.7244\n",
      "Epoch 17/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5210 - accuracy: 0.7441 - val_loss: 0.5206 - val_accuracy: 0.7444\n",
      "Epoch 18/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5153 - accuracy: 0.7565 - val_loss: 0.5164 - val_accuracy: 0.7469\n",
      "Epoch 19/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5093 - accuracy: 0.7565 - val_loss: 0.5097 - val_accuracy: 0.7494\n",
      "Epoch 20/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5039 - accuracy: 0.7609 - val_loss: 0.5046 - val_accuracy: 0.7618\n",
      "Epoch 21/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4993 - accuracy: 0.7632 - val_loss: 0.5006 - val_accuracy: 0.7631\n",
      "Epoch 22/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4948 - accuracy: 0.7722 - val_loss: 0.4967 - val_accuracy: 0.7756\n",
      "Epoch 23/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4909 - accuracy: 0.7789 - val_loss: 0.4931 - val_accuracy: 0.7830\n",
      "Epoch 24/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4870 - accuracy: 0.7823 - val_loss: 0.4907 - val_accuracy: 0.7805\n",
      "Epoch 25/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4851 - accuracy: 0.7856 - val_loss: 0.4882 - val_accuracy: 0.7830\n",
      "Epoch 26/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4838 - accuracy: 0.7834 - val_loss: 0.4860 - val_accuracy: 0.7918\n",
      "Epoch 27/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4815 - accuracy: 0.7868 - val_loss: 0.4838 - val_accuracy: 0.7893\n",
      "Epoch 28/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.7935 - val_loss: 0.4820 - val_accuracy: 0.7905\n",
      "Epoch 29/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4771 - accuracy: 0.7912 - val_loss: 0.4791 - val_accuracy: 0.7980\n",
      "Epoch 30/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4736 - accuracy: 0.8013 - val_loss: 0.4777 - val_accuracy: 0.7980\n",
      "Epoch 31/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4713 - accuracy: 0.7957 - val_loss: 0.4749 - val_accuracy: 0.7943\n",
      "Epoch 32/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4704 - accuracy: 0.8002 - val_loss: 0.4761 - val_accuracy: 0.7955\n",
      "Epoch 33/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4683 - accuracy: 0.7969 - val_loss: 0.4714 - val_accuracy: 0.7955\n",
      "Epoch 34/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4659 - accuracy: 0.7924 - val_loss: 0.4699 - val_accuracy: 0.7955\n",
      "Epoch 35/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4646 - accuracy: 0.7991 - val_loss: 0.4679 - val_accuracy: 0.7943\n",
      "Epoch 36/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4628 - accuracy: 0.7946 - val_loss: 0.4660 - val_accuracy: 0.7893\n",
      "Epoch 37/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4601 - accuracy: 0.7901 - val_loss: 0.4635 - val_accuracy: 0.7905\n",
      "Epoch 38/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4586 - accuracy: 0.7935 - val_loss: 0.4626 - val_accuracy: 0.7943\n",
      "Epoch 39/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4568 - accuracy: 0.7946 - val_loss: 0.4598 - val_accuracy: 0.7918\n",
      "Epoch 40/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4549 - accuracy: 0.7957 - val_loss: 0.4590 - val_accuracy: 0.7943\n",
      "Epoch 41/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4535 - accuracy: 0.7924 - val_loss: 0.4572 - val_accuracy: 0.7918\n",
      "Epoch 42/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4528 - accuracy: 0.7924 - val_loss: 0.4569 - val_accuracy: 0.7955\n",
      "Epoch 43/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4528 - accuracy: 0.7991 - val_loss: 0.4544 - val_accuracy: 0.7905\n",
      "Epoch 44/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4495 - accuracy: 0.7924 - val_loss: 0.4531 - val_accuracy: 0.7943\n",
      "Epoch 45/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4487 - accuracy: 0.7957 - val_loss: 0.4517 - val_accuracy: 0.7930\n",
      "Epoch 46/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4467 - accuracy: 0.7969 - val_loss: 0.4502 - val_accuracy: 0.7943\n",
      "Epoch 47/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4453 - accuracy: 0.7969 - val_loss: 0.4481 - val_accuracy: 0.7943\n",
      "Epoch 48/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4433 - accuracy: 0.7969 - val_loss: 0.4465 - val_accuracy: 0.7943\n",
      "Epoch 49/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.4485 - val_accuracy: 0.7993\n",
      "Epoch 50/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4424 - accuracy: 0.8002 - val_loss: 0.4436 - val_accuracy: 0.7955\n",
      "Epoch 51/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.4423 - val_accuracy: 0.7955\n",
      "Epoch 52/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.4412 - val_accuracy: 0.7955\n",
      "Epoch 53/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.4387 - val_accuracy: 0.7955\n",
      "Epoch 54/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4354 - accuracy: 0.7957 - val_loss: 0.4386 - val_accuracy: 0.7980\n",
      "Epoch 55/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4345 - accuracy: 0.7980 - val_loss: 0.4370 - val_accuracy: 0.7918\n",
      "Epoch 56/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4348 - accuracy: 0.7957 - val_loss: 0.4360 - val_accuracy: 0.7993\n",
      "Epoch 57/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.7980 - val_loss: 0.4337 - val_accuracy: 0.7993\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4292 - accuracy: 0.7980 - val_loss: 0.4322 - val_accuracy: 0.8005\n",
      "Epoch 59/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4284 - accuracy: 0.7957 - val_loss: 0.4307 - val_accuracy: 0.7993\n",
      "Epoch 60/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4277 - accuracy: 0.7980 - val_loss: 0.4299 - val_accuracy: 0.8005\n",
      "Epoch 61/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.7991 - val_loss: 0.4282 - val_accuracy: 0.7993\n",
      "Epoch 62/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4251 - accuracy: 0.7980 - val_loss: 0.4275 - val_accuracy: 0.8005\n",
      "Epoch 63/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4252 - accuracy: 0.8002 - val_loss: 0.4278 - val_accuracy: 0.8055\n",
      "Epoch 64/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4253 - accuracy: 0.8036 - val_loss: 0.4274 - val_accuracy: 0.8042\n",
      "Epoch 65/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4240 - accuracy: 0.8025 - val_loss: 0.4257 - val_accuracy: 0.8042\n",
      "Epoch 66/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4222 - accuracy: 0.8025 - val_loss: 0.4236 - val_accuracy: 0.8042\n",
      "Epoch 67/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4225 - accuracy: 0.7980 - val_loss: 0.4239 - val_accuracy: 0.8055\n",
      "Epoch 68/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4220 - accuracy: 0.8036 - val_loss: 0.4257 - val_accuracy: 0.8055\n",
      "Epoch 69/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4193 - accuracy: 0.8070 - val_loss: 0.4215 - val_accuracy: 0.8105\n",
      "Epoch 70/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4204 - accuracy: 0.8036 - val_loss: 0.4211 - val_accuracy: 0.8080\n",
      "Epoch 71/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.8047 - val_loss: 0.4199 - val_accuracy: 0.8067\n",
      "Epoch 72/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.8070 - val_loss: 0.4199 - val_accuracy: 0.8117\n",
      "Epoch 73/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4174 - accuracy: 0.8103 - val_loss: 0.4184 - val_accuracy: 0.8105\n",
      "Epoch 74/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4167 - accuracy: 0.8103 - val_loss: 0.4178 - val_accuracy: 0.8117\n",
      "Epoch 75/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4183 - accuracy: 0.8081 - val_loss: 0.4193 - val_accuracy: 0.8067\n",
      "Epoch 76/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4149 - accuracy: 0.8092 - val_loss: 0.4161 - val_accuracy: 0.8105\n",
      "Epoch 77/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4151 - accuracy: 0.8058 - val_loss: 0.4149 - val_accuracy: 0.8130\n",
      "Epoch 78/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4134 - accuracy: 0.8081 - val_loss: 0.4147 - val_accuracy: 0.8117\n",
      "Epoch 79/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.8114 - val_loss: 0.4136 - val_accuracy: 0.8155\n",
      "Epoch 80/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4135 - accuracy: 0.8081 - val_loss: 0.4138 - val_accuracy: 0.8092\n",
      "Epoch 81/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4125 - accuracy: 0.8070 - val_loss: 0.4125 - val_accuracy: 0.8142\n",
      "Epoch 82/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4114 - accuracy: 0.8081 - val_loss: 0.4119 - val_accuracy: 0.8155\n",
      "Epoch 83/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4114 - accuracy: 0.8047 - val_loss: 0.4109 - val_accuracy: 0.8155\n",
      "Epoch 84/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4094 - accuracy: 0.8137 - val_loss: 0.4158 - val_accuracy: 0.8142\n",
      "Epoch 85/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4134 - accuracy: 0.8081 - val_loss: 0.4102 - val_accuracy: 0.8167\n",
      "Epoch 86/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4093 - accuracy: 0.8114 - val_loss: 0.4097 - val_accuracy: 0.8167\n",
      "Epoch 87/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4079 - accuracy: 0.8159 - val_loss: 0.4087 - val_accuracy: 0.8142\n",
      "Epoch 88/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.8114 - val_loss: 0.4076 - val_accuracy: 0.8167\n",
      "Epoch 89/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4085 - accuracy: 0.8159 - val_loss: 0.4093 - val_accuracy: 0.8167\n",
      "Epoch 90/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4115 - accuracy: 0.8103 - val_loss: 0.4069 - val_accuracy: 0.8180\n",
      "Epoch 91/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.8137 - val_loss: 0.4051 - val_accuracy: 0.8204\n",
      "Epoch 92/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4041 - accuracy: 0.8103 - val_loss: 0.4053 - val_accuracy: 0.8180\n",
      "Epoch 93/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4043 - accuracy: 0.8148 - val_loss: 0.4036 - val_accuracy: 0.8204\n",
      "Epoch 94/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4024 - accuracy: 0.8182 - val_loss: 0.4047 - val_accuracy: 0.8180\n",
      "Epoch 95/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4028 - accuracy: 0.8215 - val_loss: 0.4013 - val_accuracy: 0.8229\n",
      "Epoch 96/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8137 - val_loss: 0.4020 - val_accuracy: 0.8229\n",
      "Epoch 97/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.8193 - val_loss: 0.4004 - val_accuracy: 0.8242\n",
      "Epoch 98/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4002 - accuracy: 0.8193 - val_loss: 0.4007 - val_accuracy: 0.8192\n",
      "Epoch 99/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4015 - accuracy: 0.8159 - val_loss: 0.4014 - val_accuracy: 0.8192\n",
      "Epoch 100/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3986 - accuracy: 0.8193 - val_loss: 0.3984 - val_accuracy: 0.8267\n",
      "Epoch 101/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.8193 - val_loss: 0.3972 - val_accuracy: 0.8267\n",
      "Epoch 102/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3972 - accuracy: 0.8182 - val_loss: 0.3964 - val_accuracy: 0.8254\n",
      "Epoch 103/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3960 - accuracy: 0.8215 - val_loss: 0.4024 - val_accuracy: 0.8229\n",
      "Epoch 104/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4001 - accuracy: 0.8182 - val_loss: 0.4032 - val_accuracy: 0.8217\n",
      "Epoch 105/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3995 - accuracy: 0.8159 - val_loss: 0.3957 - val_accuracy: 0.8254\n",
      "Epoch 106/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3951 - accuracy: 0.8159 - val_loss: 0.4001 - val_accuracy: 0.8217\n",
      "Epoch 107/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.8193 - val_loss: 0.3967 - val_accuracy: 0.8242\n",
      "Epoch 108/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3939 - accuracy: 0.8238 - val_loss: 0.3956 - val_accuracy: 0.8267\n",
      "Epoch 109/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3941 - accuracy: 0.8159 - val_loss: 0.3940 - val_accuracy: 0.8279\n",
      "Epoch 110/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3951 - accuracy: 0.8260 - val_loss: 0.3945 - val_accuracy: 0.8254\n",
      "Epoch 111/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3928 - accuracy: 0.8227 - val_loss: 0.3926 - val_accuracy: 0.8292\n",
      "Epoch 112/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8283 - val_loss: 0.3978 - val_accuracy: 0.8279\n",
      "Epoch 113/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.8171 - val_loss: 0.3925 - val_accuracy: 0.8279\n",
      "Epoch 114/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3896 - accuracy: 0.8204 - val_loss: 0.3909 - val_accuracy: 0.8292\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3911 - accuracy: 0.8215 - val_loss: 0.3899 - val_accuracy: 0.8279\n",
      "Epoch 116/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8238 - val_loss: 0.3889 - val_accuracy: 0.8292\n",
      "Epoch 117/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3895 - accuracy: 0.8193 - val_loss: 0.3892 - val_accuracy: 0.8292\n",
      "Epoch 118/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3893 - accuracy: 0.8227 - val_loss: 0.3889 - val_accuracy: 0.8279\n",
      "Epoch 119/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.8227 - val_loss: 0.3895 - val_accuracy: 0.8292\n",
      "Epoch 120/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8204 - val_loss: 0.3924 - val_accuracy: 0.8254\n",
      "Epoch 121/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3925 - accuracy: 0.8283 - val_loss: 0.3889 - val_accuracy: 0.8279\n",
      "Epoch 122/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3881 - accuracy: 0.8249 - val_loss: 0.3912 - val_accuracy: 0.8279\n",
      "Epoch 123/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3865 - accuracy: 0.8204 - val_loss: 0.3856 - val_accuracy: 0.8279\n",
      "Epoch 124/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3867 - accuracy: 0.8238 - val_loss: 0.3890 - val_accuracy: 0.8254\n",
      "Epoch 125/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.8227 - val_loss: 0.3849 - val_accuracy: 0.8292\n",
      "Epoch 126/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3857 - accuracy: 0.8215 - val_loss: 0.3840 - val_accuracy: 0.8304\n",
      "Epoch 127/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3851 - accuracy: 0.8238 - val_loss: 0.3839 - val_accuracy: 0.8292\n",
      "Epoch 128/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3908 - accuracy: 0.8283 - val_loss: 0.3845 - val_accuracy: 0.8304\n",
      "Epoch 129/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8272 - val_loss: 0.3890 - val_accuracy: 0.8292\n",
      "Epoch 130/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3847 - accuracy: 0.8227 - val_loss: 0.3828 - val_accuracy: 0.8342\n",
      "Epoch 131/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.8249 - val_loss: 0.3817 - val_accuracy: 0.8304\n",
      "Epoch 132/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3840 - accuracy: 0.8227 - val_loss: 0.3873 - val_accuracy: 0.8292\n",
      "Epoch 133/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3835 - accuracy: 0.8249 - val_loss: 0.3809 - val_accuracy: 0.8304\n",
      "Epoch 134/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.8227 - val_loss: 0.3810 - val_accuracy: 0.8317\n",
      "Epoch 135/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3820 - accuracy: 0.8283 - val_loss: 0.3812 - val_accuracy: 0.8279\n",
      "Epoch 136/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3846 - accuracy: 0.8227 - val_loss: 0.3806 - val_accuracy: 0.8304\n",
      "Epoch 137/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3804 - accuracy: 0.8260 - val_loss: 0.3818 - val_accuracy: 0.8292\n",
      "Epoch 138/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3812 - accuracy: 0.8227 - val_loss: 0.3796 - val_accuracy: 0.8292\n",
      "Epoch 139/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3810 - accuracy: 0.8215 - val_loss: 0.3876 - val_accuracy: 0.8367\n",
      "Epoch 140/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3800 - accuracy: 0.8305 - val_loss: 0.3785 - val_accuracy: 0.8292\n",
      "Epoch 141/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3807 - accuracy: 0.8204 - val_loss: 0.3788 - val_accuracy: 0.8279\n",
      "Epoch 142/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3786 - accuracy: 0.8283 - val_loss: 0.3782 - val_accuracy: 0.8292\n",
      "Epoch 143/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3842 - accuracy: 0.8272 - val_loss: 0.3781 - val_accuracy: 0.8267\n",
      "Epoch 144/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3834 - accuracy: 0.8238 - val_loss: 0.3776 - val_accuracy: 0.8279\n",
      "Epoch 145/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8272 - val_loss: 0.3801 - val_accuracy: 0.8304\n",
      "Epoch 146/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8361 - val_loss: 0.3763 - val_accuracy: 0.8267\n",
      "Epoch 147/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3810 - accuracy: 0.8238 - val_loss: 0.3748 - val_accuracy: 0.8317\n",
      "Epoch 148/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3781 - accuracy: 0.8294 - val_loss: 0.3746 - val_accuracy: 0.8317\n",
      "Epoch 149/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3776 - accuracy: 0.8294 - val_loss: 0.3741 - val_accuracy: 0.8279\n",
      "Epoch 150/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3778 - accuracy: 0.8272 - val_loss: 0.3743 - val_accuracy: 0.8292\n",
      "Epoch 151/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3753 - accuracy: 0.8227 - val_loss: 0.3741 - val_accuracy: 0.8267\n",
      "Epoch 152/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3754 - accuracy: 0.8204 - val_loss: 0.3738 - val_accuracy: 0.8292\n",
      "Epoch 153/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3770 - accuracy: 0.8272 - val_loss: 0.3740 - val_accuracy: 0.8292\n",
      "Epoch 154/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8238 - val_loss: 0.3741 - val_accuracy: 0.8279\n",
      "Epoch 155/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.8227 - val_loss: 0.3738 - val_accuracy: 0.8292\n",
      "Epoch 156/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3740 - accuracy: 0.8260 - val_loss: 0.3788 - val_accuracy: 0.8367\n",
      "Epoch 157/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8238 - val_loss: 0.3730 - val_accuracy: 0.8267\n",
      "Epoch 158/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3750 - accuracy: 0.8215 - val_loss: 0.3718 - val_accuracy: 0.8279\n",
      "Epoch 159/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3753 - accuracy: 0.8227 - val_loss: 0.3715 - val_accuracy: 0.8304\n",
      "Epoch 160/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3758 - accuracy: 0.8305 - val_loss: 0.3711 - val_accuracy: 0.8304\n",
      "Epoch 161/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3802 - accuracy: 0.8238 - val_loss: 0.3733 - val_accuracy: 0.8292\n",
      "Epoch 162/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3735 - accuracy: 0.8238 - val_loss: 0.3726 - val_accuracy: 0.8342\n",
      "Epoch 163/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3756 - accuracy: 0.8238 - val_loss: 0.3754 - val_accuracy: 0.8354\n",
      "Epoch 164/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3735 - accuracy: 0.8272 - val_loss: 0.3711 - val_accuracy: 0.8292\n",
      "Epoch 165/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8249 - val_loss: 0.3704 - val_accuracy: 0.8317\n",
      "Epoch 166/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8283 - val_loss: 0.3694 - val_accuracy: 0.8317\n",
      "Epoch 167/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3701 - accuracy: 0.8272 - val_loss: 0.3693 - val_accuracy: 0.8342\n",
      "Epoch 168/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3745 - accuracy: 0.8249 - val_loss: 0.3736 - val_accuracy: 0.8329\n",
      "Epoch 169/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3854 - accuracy: 0.8215 - val_loss: 0.3718 - val_accuracy: 0.8304\n",
      "Epoch 170/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3962 - accuracy: 0.8249 - val_loss: 0.3741 - val_accuracy: 0.8379\n",
      "Epoch 171/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3704 - accuracy: 0.8260 - val_loss: 0.3710 - val_accuracy: 0.8317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3718 - accuracy: 0.8272 - val_loss: 0.3680 - val_accuracy: 0.8367\n",
      "Epoch 173/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.8272 - val_loss: 0.3684 - val_accuracy: 0.8342\n",
      "Epoch 174/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3689 - accuracy: 0.8283 - val_loss: 0.3668 - val_accuracy: 0.8379\n",
      "Epoch 175/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3686 - accuracy: 0.8272 - val_loss: 0.3657 - val_accuracy: 0.8367\n",
      "Epoch 176/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3711 - accuracy: 0.8283 - val_loss: 0.3670 - val_accuracy: 0.8329\n",
      "Epoch 177/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.8283 - val_loss: 0.3666 - val_accuracy: 0.8342\n",
      "Epoch 178/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3703 - accuracy: 0.8272 - val_loss: 0.3731 - val_accuracy: 0.8379\n",
      "Epoch 179/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8260 - val_loss: 0.3692 - val_accuracy: 0.8379\n",
      "Epoch 180/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3668 - accuracy: 0.8339 - val_loss: 0.3647 - val_accuracy: 0.8367\n",
      "Epoch 181/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3687 - accuracy: 0.8305 - val_loss: 0.3653 - val_accuracy: 0.8392\n",
      "Epoch 182/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3660 - accuracy: 0.8350 - val_loss: 0.3655 - val_accuracy: 0.8392\n",
      "Epoch 183/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3674 - accuracy: 0.8328 - val_loss: 0.3641 - val_accuracy: 0.8342\n",
      "Epoch 184/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3650 - accuracy: 0.8294 - val_loss: 0.3633 - val_accuracy: 0.8354\n",
      "Epoch 185/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3671 - accuracy: 0.8305 - val_loss: 0.3660 - val_accuracy: 0.8404\n",
      "Epoch 186/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3657 - accuracy: 0.8361 - val_loss: 0.3636 - val_accuracy: 0.8317\n",
      "Epoch 187/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3660 - accuracy: 0.8328 - val_loss: 0.3664 - val_accuracy: 0.8379\n",
      "Epoch 188/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8373 - val_loss: 0.3638 - val_accuracy: 0.8379\n",
      "Epoch 189/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3681 - accuracy: 0.8339 - val_loss: 0.3632 - val_accuracy: 0.8392\n",
      "Epoch 190/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.8350 - val_loss: 0.3664 - val_accuracy: 0.8342\n",
      "Epoch 191/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3693 - accuracy: 0.8294 - val_loss: 0.3627 - val_accuracy: 0.8404\n",
      "Epoch 192/300\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3651 - accuracy: 0.8294 - val_loss: 0.3619 - val_accuracy: 0.8367\n",
      "Epoch 193/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3651 - accuracy: 0.8316 - val_loss: 0.3613 - val_accuracy: 0.8342\n",
      "Epoch 194/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8305 - val_loss: 0.3608 - val_accuracy: 0.8367\n",
      "Epoch 195/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3648 - accuracy: 0.8260 - val_loss: 0.3631 - val_accuracy: 0.8367\n",
      "Epoch 196/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.8350 - val_loss: 0.3634 - val_accuracy: 0.8317\n",
      "Epoch 197/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3636 - accuracy: 0.8305 - val_loss: 0.3641 - val_accuracy: 0.8354\n",
      "Epoch 198/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3685 - accuracy: 0.8328 - val_loss: 0.3608 - val_accuracy: 0.8392\n",
      "Epoch 199/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.8328 - val_loss: 0.3601 - val_accuracy: 0.8404\n",
      "Epoch 200/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3619 - accuracy: 0.8350 - val_loss: 0.3606 - val_accuracy: 0.8379\n",
      "Epoch 201/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3650 - accuracy: 0.8272 - val_loss: 0.3594 - val_accuracy: 0.8379\n",
      "Epoch 202/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.8305 - val_loss: 0.3642 - val_accuracy: 0.8329\n",
      "Epoch 203/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8283 - val_loss: 0.3628 - val_accuracy: 0.8367\n",
      "Epoch 204/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.8103 - val_loss: 0.4122 - val_accuracy: 0.8180\n",
      "Epoch 205/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3983 - accuracy: 0.8215 - val_loss: 0.3740 - val_accuracy: 0.8317\n",
      "Epoch 206/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3685 - accuracy: 0.8260 - val_loss: 0.3651 - val_accuracy: 0.8267\n",
      "Epoch 207/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.8260 - val_loss: 0.3642 - val_accuracy: 0.8342\n",
      "Epoch 208/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3621 - accuracy: 0.8339 - val_loss: 0.3630 - val_accuracy: 0.8342\n",
      "Epoch 209/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3615 - accuracy: 0.8328 - val_loss: 0.3617 - val_accuracy: 0.8329\n",
      "Epoch 210/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8305 - val_loss: 0.3593 - val_accuracy: 0.8342\n",
      "Epoch 211/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3635 - accuracy: 0.8294 - val_loss: 0.3603 - val_accuracy: 0.8367\n",
      "Epoch 212/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8305 - val_loss: 0.3655 - val_accuracy: 0.8317\n",
      "Epoch 213/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3589 - accuracy: 0.8328 - val_loss: 0.3620 - val_accuracy: 0.8354\n",
      "Epoch 214/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.8361 - val_loss: 0.3585 - val_accuracy: 0.8329\n",
      "Epoch 215/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3589 - accuracy: 0.8294 - val_loss: 0.3588 - val_accuracy: 0.8367\n",
      "Epoch 216/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8350 - val_loss: 0.3598 - val_accuracy: 0.8342\n",
      "Epoch 217/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8294 - val_loss: 0.3578 - val_accuracy: 0.8342\n",
      "Epoch 218/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3595 - accuracy: 0.8294 - val_loss: 0.3563 - val_accuracy: 0.8379\n",
      "Epoch 219/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3593 - accuracy: 0.8328 - val_loss: 0.3561 - val_accuracy: 0.8392\n",
      "Epoch 220/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8339 - val_loss: 0.3579 - val_accuracy: 0.8379\n",
      "Epoch 221/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3641 - accuracy: 0.8339 - val_loss: 0.3582 - val_accuracy: 0.8354\n",
      "Epoch 222/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8283 - val_loss: 0.3743 - val_accuracy: 0.8342\n",
      "Epoch 223/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8316 - val_loss: 0.3577 - val_accuracy: 0.8342\n",
      "Epoch 224/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3576 - accuracy: 0.8339 - val_loss: 0.3569 - val_accuracy: 0.8329\n",
      "Epoch 225/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3577 - accuracy: 0.8294 - val_loss: 0.3562 - val_accuracy: 0.8317\n",
      "Epoch 226/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8328 - val_loss: 0.3580 - val_accuracy: 0.8354\n",
      "Epoch 227/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3594 - accuracy: 0.8361 - val_loss: 0.3585 - val_accuracy: 0.8367\n",
      "Epoch 228/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.8260 - val_loss: 0.3557 - val_accuracy: 0.8354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 0.8350 - val_loss: 0.3569 - val_accuracy: 0.8354\n",
      "Epoch 230/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3576 - accuracy: 0.8328 - val_loss: 0.3593 - val_accuracy: 0.8354\n",
      "Epoch 231/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4105 - accuracy: 0.8272 - val_loss: 0.6270 - val_accuracy: 0.7943\n",
      "Epoch 232/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8159 - val_loss: 0.4159 - val_accuracy: 0.8055\n",
      "Epoch 233/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3906 - accuracy: 0.8193 - val_loss: 0.3837 - val_accuracy: 0.8317\n",
      "Epoch 234/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3748 - accuracy: 0.8238 - val_loss: 0.3703 - val_accuracy: 0.8329\n",
      "Epoch 235/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3654 - accuracy: 0.8283 - val_loss: 0.3626 - val_accuracy: 0.8317\n",
      "Epoch 236/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3617 - accuracy: 0.8272 - val_loss: 0.3630 - val_accuracy: 0.8367\n",
      "Epoch 237/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3602 - accuracy: 0.8283 - val_loss: 0.3578 - val_accuracy: 0.8317\n",
      "Epoch 238/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.8294 - val_loss: 0.3566 - val_accuracy: 0.8342\n",
      "Epoch 239/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3568 - accuracy: 0.8272 - val_loss: 0.3559 - val_accuracy: 0.8329\n",
      "Epoch 240/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.8328 - val_loss: 0.3557 - val_accuracy: 0.8354\n",
      "Epoch 241/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3571 - accuracy: 0.8305 - val_loss: 0.3548 - val_accuracy: 0.8342\n",
      "Epoch 242/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3575 - accuracy: 0.8316 - val_loss: 0.3550 - val_accuracy: 0.8354\n",
      "Epoch 243/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3586 - accuracy: 0.8361 - val_loss: 0.3552 - val_accuracy: 0.8342\n",
      "Epoch 244/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3599 - accuracy: 0.8339 - val_loss: 0.3554 - val_accuracy: 0.8379\n",
      "Epoch 245/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3559 - accuracy: 0.8328 - val_loss: 0.3544 - val_accuracy: 0.8354\n",
      "Epoch 246/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3583 - accuracy: 0.8361 - val_loss: 0.3567 - val_accuracy: 0.8367\n",
      "Epoch 247/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3561 - accuracy: 0.8305 - val_loss: 0.3535 - val_accuracy: 0.8329\n",
      "Epoch 248/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3553 - accuracy: 0.8272 - val_loss: 0.3526 - val_accuracy: 0.8354\n",
      "Epoch 249/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3551 - accuracy: 0.8373 - val_loss: 0.3546 - val_accuracy: 0.8317\n",
      "Epoch 250/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3549 - accuracy: 0.8328 - val_loss: 0.3531 - val_accuracy: 0.8367\n",
      "Epoch 251/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3563 - accuracy: 0.8305 - val_loss: 0.3524 - val_accuracy: 0.8379\n",
      "Epoch 252/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.8373 - val_loss: 0.3573 - val_accuracy: 0.8354\n",
      "Epoch 253/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3557 - accuracy: 0.8294 - val_loss: 0.3525 - val_accuracy: 0.8367\n",
      "Epoch 254/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3546 - accuracy: 0.8316 - val_loss: 0.3526 - val_accuracy: 0.8379\n",
      "Epoch 255/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.8373 - val_loss: 0.3516 - val_accuracy: 0.8367\n",
      "Epoch 256/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8316 - val_loss: 0.3519 - val_accuracy: 0.8342\n",
      "Epoch 257/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3544 - accuracy: 0.8283 - val_loss: 0.3558 - val_accuracy: 0.8329\n",
      "Epoch 258/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8294 - val_loss: 0.3518 - val_accuracy: 0.8392\n",
      "Epoch 259/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.8373 - val_loss: 0.3509 - val_accuracy: 0.8354\n",
      "Epoch 260/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3564 - accuracy: 0.8316 - val_loss: 0.3505 - val_accuracy: 0.8367\n",
      "Epoch 261/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3540 - accuracy: 0.8316 - val_loss: 0.3503 - val_accuracy: 0.8342\n",
      "Epoch 262/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3553 - accuracy: 0.8328 - val_loss: 0.3517 - val_accuracy: 0.8342\n",
      "Epoch 263/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.8328 - val_loss: 0.3536 - val_accuracy: 0.8379\n",
      "Epoch 264/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3530 - accuracy: 0.8328 - val_loss: 0.3505 - val_accuracy: 0.8379\n",
      "Epoch 265/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3540 - accuracy: 0.8283 - val_loss: 0.3522 - val_accuracy: 0.8392\n",
      "Epoch 266/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3553 - accuracy: 0.8316 - val_loss: 0.3514 - val_accuracy: 0.8317\n",
      "Epoch 267/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3557 - accuracy: 0.8305 - val_loss: 0.3498 - val_accuracy: 0.8342\n",
      "Epoch 268/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3537 - accuracy: 0.8328 - val_loss: 0.3534 - val_accuracy: 0.8392\n",
      "Epoch 269/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3545 - accuracy: 0.8373 - val_loss: 0.3503 - val_accuracy: 0.8379\n",
      "Epoch 270/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3520 - accuracy: 0.8384 - val_loss: 0.3502 - val_accuracy: 0.8379\n",
      "Epoch 271/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3529 - accuracy: 0.8350 - val_loss: 0.3549 - val_accuracy: 0.8404\n",
      "Epoch 272/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3659 - accuracy: 0.8294 - val_loss: 0.4025 - val_accuracy: 0.8292\n",
      "Epoch 273/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3649 - accuracy: 0.8339 - val_loss: 0.3535 - val_accuracy: 0.8342\n",
      "Epoch 274/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3548 - accuracy: 0.8328 - val_loss: 0.3509 - val_accuracy: 0.8367\n",
      "Epoch 275/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3524 - accuracy: 0.8361 - val_loss: 0.3510 - val_accuracy: 0.8367\n",
      "Epoch 276/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3529 - accuracy: 0.8316 - val_loss: 0.3500 - val_accuracy: 0.8329\n",
      "Epoch 277/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3523 - accuracy: 0.8294 - val_loss: 0.3487 - val_accuracy: 0.8329\n",
      "Epoch 278/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3534 - accuracy: 0.8339 - val_loss: 0.3506 - val_accuracy: 0.8404\n",
      "Epoch 279/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3506 - accuracy: 0.8350 - val_loss: 0.3500 - val_accuracy: 0.8404\n",
      "Epoch 280/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3696 - accuracy: 0.8272 - val_loss: 0.3510 - val_accuracy: 0.8342\n",
      "Epoch 281/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3526 - accuracy: 0.8328 - val_loss: 0.3648 - val_accuracy: 0.8379\n",
      "Epoch 282/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3559 - accuracy: 0.8373 - val_loss: 0.3487 - val_accuracy: 0.8367\n",
      "Epoch 283/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3494 - accuracy: 0.8316 - val_loss: 0.3475 - val_accuracy: 0.8392\n",
      "Epoch 284/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3519 - accuracy: 0.8350 - val_loss: 0.3479 - val_accuracy: 0.8354\n",
      "Epoch 285/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8283 - val_loss: 0.3514 - val_accuracy: 0.8342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3519 - accuracy: 0.8350 - val_loss: 0.3515 - val_accuracy: 0.8392\n",
      "Epoch 287/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3549 - accuracy: 0.8350 - val_loss: 0.3618 - val_accuracy: 0.8392\n",
      "Epoch 288/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3653 - accuracy: 0.8227 - val_loss: 0.3881 - val_accuracy: 0.8342\n",
      "Epoch 289/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3789 - accuracy: 0.8328 - val_loss: 0.3694 - val_accuracy: 0.8379\n",
      "Epoch 290/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3604 - accuracy: 0.8305 - val_loss: 0.3509 - val_accuracy: 0.8329\n",
      "Epoch 291/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3517 - accuracy: 0.8328 - val_loss: 0.3519 - val_accuracy: 0.8354\n",
      "Epoch 292/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3537 - accuracy: 0.8305 - val_loss: 0.3520 - val_accuracy: 0.8404\n",
      "Epoch 293/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8339 - val_loss: 0.3517 - val_accuracy: 0.8367\n",
      "Epoch 294/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3538 - accuracy: 0.8350 - val_loss: 0.3526 - val_accuracy: 0.8379\n",
      "Epoch 295/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.8305 - val_loss: 0.3502 - val_accuracy: 0.8329\n",
      "Epoch 296/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3532 - accuracy: 0.8316 - val_loss: 0.3517 - val_accuracy: 0.8429\n",
      "Epoch 297/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3499 - accuracy: 0.8316 - val_loss: 0.3538 - val_accuracy: 0.8416\n",
      "Epoch 298/300\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3585 - accuracy: 0.8361 - val_loss: 0.5202 - val_accuracy: 0.8055\n",
      "Epoch 299/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4069 - accuracy: 0.8204 - val_loss: 0.3790 - val_accuracy: 0.8242\n",
      "Epoch 300/300\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.8272 - val_loss: 0.3595 - val_accuracy: 0.8329\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8316\n",
      "Training accuracy: 0.8316498398780823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a seModeloquential model\n",
    "## Viene de KERAS!\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=len(titanic_x_names),\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# Segunda capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=hidden_units, \n",
    "                       activation='relu'))\n",
    "\n",
    "# Tercera capa oculta de 20 nodos\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=hidden_units, \n",
    "                       activation='relu'))\n",
    "\n",
    "# final de la red, outputs\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='relu'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit(titanic_X_norm, titanic_y, epochs=epochs, batch_size=batch_size, validation_data= (X_val, y_val))\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(titanic_X_norm, titanic_y, batch_size=32)[1]\n",
    "#test_acc = model.evaluate(X_test, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "#print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec470320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
